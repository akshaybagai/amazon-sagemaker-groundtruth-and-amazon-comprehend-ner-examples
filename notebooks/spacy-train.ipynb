{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:250%; font-weight:bold\">Train NER with SpaCy</div>\n",
    "\n",
    "This notebook shows how to train a new NER model from scratch using the SpaCy library on Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import s3fs\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker.session import s3_input\n",
    "\n",
    "from gtner_blog.util import split, write_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Note</summary>\n",
    "    <blockquote>Choose the existing MXNet container, so we don't have to create a new container image.</blockquote>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data channels\n",
    "\n",
    "Split the whole corpus into train:test = 3:1 proportion, then upload the splits to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'gtner-blog'                # Change me as necessary\n",
    "gt_jobname = 'test-gtner-blog-004'   # Change me as necessary\n",
    "\n",
    "iob_file = f's3://{bucket}/gt/{gt_jobname}/manifests/output/output.iob'\n",
    "train = f's3://{bucket}/spacy-data/train'\n",
    "test = f's3://{bucket}/spacy-data/test'\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "with fs.open(iob_file, 'r') as f:\n",
    "    train_split = os.path.join(train, 'data.iob')\n",
    "    test_split = os.path.join(test, 'data.iob')\n",
    "\n",
    "    # Chain of functions: .iob > split -> write_split.\n",
    "    write_split(split(f), train_split, test_split)\n",
    "\n",
    "display(iob_file, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training\n",
    "\n",
    "We create an MXNet estimator with our entry point script `spacy-train.py`, a thin wrapper over `spacy train ...` CLI that does the following:\n",
    "\n",
    "1. parse SageMaker's entry-point protocol, namely model and channel directories.\n",
    "2. pre-define a few arguments to `spacy train ...` CLI: `{\"--lang\", \"--pipeline\", \"--output_path\", \"--train_path\", \"--dev_path\"}`.\n",
    "3. passes the estimator's hyper-parameters as arguments to `spacy train ...`.\n",
    "   1. Each hyperparameter `abcd` will be passed down as `--abcd`.\n",
    "   2. The hyperparameters must not conflict with those in the above mentioned step 2.\n",
    "   3. The entry point only support `--abcd SOME_VALUE` form of arguments.\n",
    "\n",
    "<details>\n",
    "    <summary><code>spacy train --help</code></summary>\n",
    "    <blockquote><pre>\n",
    "usage: spacy train [-h] [-rt None] [-b None] [-p tagger,parser,ner] [-v None]\n",
    "                   [-n 30] [-ne None] [-ns 0] [-g -1] [-V 0.0.0] [-m None]\n",
    "                   [-t2v None] [-pt] [-et] [-nl 0.0] [-ovl 0.0] [-bw] [-G]\n",
    "                   [-T] [-TML] [-ta bow] [-tpl None] [-VV] [-D]\n",
    "                   lang output_path train_path dev_path\n",
    "\n",
    "    Train or update a spaCy model. Requires data to be formatted in spaCy's\n",
    "    JSON format. To convert data from other formats, use the `spacy convert`\n",
    "    command.\n",
    "\n",
    "\n",
    "positional arguments:\n",
    "  lang                  Model language\n",
    "  output_path           Output directory to store model in\n",
    "  train_path            Location of JSON-formatted training data\n",
    "  dev_path              Location of JSON-formatted development data\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -rt None, --raw-text None\n",
    "                        Path to jsonl file with unlabelled text documents.\n",
    "  -b None, --base-model None\n",
    "                        Name of model to update (optional)\n",
    "  -p tagger,parser,ner, --pipeline tagger,parser,ner\n",
    "                        Comma-separated names of pipeline components\n",
    "  -v None, --vectors None\n",
    "                        Model to load vectors from\n",
    "  -n 30, --n-iter 30    Number of iterations\n",
    "  -ne None, --n-early-stopping None\n",
    "                        Maximum number of training epochs without dev accuracy\n",
    "                        improvement\n",
    "  -ns 0, --n-examples 0\n",
    "                        Number of examples\n",
    "  -g -1, --use-gpu -1   Use GPU\n",
    "  -V 0.0.0, --version 0.0.0\n",
    "                        Model version\n",
    "  -m None, --meta-path None\n",
    "                        Optional path to meta.json to use as base.\n",
    "  -t2v None, --init-tok2vec None\n",
    "                        Path to pretrained weights for the token-to-vector\n",
    "                        parts of the models. See 'spacy pretrain'.\n",
    "                        Experimental.\n",
    "  -pt , --parser-multitasks\n",
    "                        Side objectives for parser CNN, e.g. 'dep' or\n",
    "                        'dep,tag'\n",
    "  -et , --entity-multitasks\n",
    "                        Side objectives for NER CNN, e.g. 'dep' or 'dep,tag'\n",
    "  -nl 0.0, --noise-level 0.0\n",
    "                        Amount of corruption for data augmentation\n",
    "  -ovl 0.0, --orth-variant-level 0.0\n",
    "                        Amount of orthography variation for data augmentation\n",
    "  -bw , --eval-beam-widths\n",
    "                        Beam widths to evaluate, e.g. 4,8\n",
    "  -G, --gold-preproc    Use gold preprocessing\n",
    "  -T, --learn-tokens    Make parser learn gold-standard tokenization\n",
    "  -TML, --textcat-multilabel\n",
    "                        Textcat classes aren't mutually exclusive (multilabel)\n",
    "  -ta bow, --textcat-arch bow\n",
    "                        Textcat model architecture\n",
    "  -tpl None, --textcat-positive-label None\n",
    "                        Textcat positive label for binary classes with two\n",
    "                        labels\n",
    "  -VV, --verbose        Display more information for debug\n",
    "  -D, --debug           Run data diagnostics before training\n",
    "</pre></blockquote>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(entry_point='spacy-train.py',\n",
    "                  source_dir='./spacy-scripts',\n",
    "                  role=get_execution_role(),\n",
    "                  train_instance_count=1,\n",
    "                  train_instance_type='ml.m5.large',\n",
    "                  framework_version='1.6.0',\n",
    "                  py_version='py3',\n",
    "                  debugger_hook_config=False,\n",
    "                  hyperparameters={'n_iter': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train': s3_input(train), 'test': s3_input(test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
