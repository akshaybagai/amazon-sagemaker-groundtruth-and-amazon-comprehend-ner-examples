{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='font-size:250%; font-weight:bold'>Train NER with huggingface/transformers</div>\n",
    "\n",
    "This notebook shows how to use `huggingface/transformers` on Amazon SageMaker to transfer-learn the Roberta language model into a new NER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "import s3fs\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.session import s3_input\n",
    "\n",
    "from gtner_blog.util import split, bilou2bio, write_split, LabelCollector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download transformers NER scripts\n",
    "\n",
    "The `huggingface/transformers` repo contains two PyTorch scripts to download, namely `run_ner.py` and `utils_ner.py`. The following `bash` cell downloads version v2.5.0 which matches the library listed in `requirements.txt`.\n",
    "\n",
    "To minimize the dependencies installed to the training container, we also download the `seqeval` into `source_dir/` to emulate `pip install --no-deps seqeval`. The `seqeval.callbacks` depends on [Keras](https://github.com/chakki-works/seqeval/blob/v0.0.12/seqeval/callbacks.py) and [tensorflow](https://github.com/chakki-works/seqeval/blob/v0.0.12/requirements.txt), but `run_ner.py` does not uses these callbacks (and only `seqeval.metrics`), hence both dependencies can be [skipped](https://github.com/chakki-works/seqeval/blob/v0.0.12/seqeval/metrics/sequence_labeling.py).\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Note</summary>\n",
    "    <blockquote>As of this writing, the master branch of <code>huggingface/transformers</code> has relocated the NER scripts from <code>examples/</code> to <code>examples/ner/</code>, which is beyond the scope of this notebook.</blockquote>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "GITHUB=https://raw.githubusercontent.com\n",
    "cd transformers-scripts\n",
    "\n",
    "# Download NER scripts\n",
    "for i in run_ner.py utils_ner.py\n",
    "do\n",
    "    curl --silent --location $GITHUB/huggingface/transformers/v2.5.0/examples/$i > $i\n",
    "done\n",
    "\n",
    "# Download seqeval\n",
    "mkdir -p seqeval/metrics\n",
    "for i in __init__.py callbacks.py metrics/__init__.py metrics/sequence_labeling.py\n",
    "do\n",
    "    curl --silent --location $GITHUB/chakki-works/seqeval/v0.0.12/seqeval/$i > seqeval/$i\n",
    "done\n",
    "\n",
    "ls -ald * seqeval/* seqeval/metrics/* | egrep --color=always 'run_ner.py|utils_ner.py|seqeval.*|^'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data channels\n",
    "\n",
    "Split the whole corpus in S3 into train:test = 3:1 proportion, then upload the splits to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'gtner-blog'                # Change me as necessary\n",
    "gt_jobname = 'test-gtner-blog-004'   # Change me as necessary\n",
    "\n",
    "iob_file = f's3://{bucket}/gt/{gt_jobname}/manifests/output/output.iob'\n",
    "train = f's3://{bucket}/transformers-data/train'\n",
    "dev = f's3://{bucket}/transformers-data/dev'\n",
    "label = f's3://{bucket}/transformers-data/label'\n",
    "label_collector = LabelCollector()\n",
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "with fs.open(iob_file, 'r') as f:\n",
    "    train_split = os.path.join(train, 'train.txt')\n",
    "    dev_split = os.path.join(dev, 'dev.txt')\n",
    "    \n",
    "    # Chain of functions: .iob -> bilou2bio -> label_collector -> split -> write_split.\n",
    "    write_split(split(label_collector(bilou2bio(f))), train_split, dev_split)\n",
    "\n",
    "with fs.open(os.path.join(label, 'label.txt'), 'w') as f:\n",
    "    for ner_tag in label_collector.sorted_labels:\n",
    "        f.write(f'{ner_tag}\\n')\n",
    "\n",
    "display(iob_file, train, dev, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training\n",
    "\n",
    "We create a PyTorch estimator with our entry point script `transformers-train.py`, a thin wrapper over `run_ner.py` that does the following:\n",
    "\n",
    "1. parse SageMaker's entry-point protocol, namely model and channel directories.\n",
    "2. pre-define a few arguments to `run-ner.py`: `{\"--do_train\", \"--do-eval\", \"--evaluate_during_train\", \"--data_dir\", \"--output_dir\", \"--label\"}`.\n",
    "3. passes the estimator's hyper-parameters as arguments to `run-ner.py`.\n",
    "   1. Each hyperparameter `abcd` will be passed down as `--abcd`.\n",
    "   2. The hyperparameters must not conflict with those in the above mentioned step 2.\n",
    "   3. The entry point only support `--abcd SOME_VALUE` form of arguments.\n",
    "\n",
    "<details>\n",
    "    <summary><code>python run_ner.py -h</code></summary>\n",
    "    <blockquote><pre>\n",
    "usage: run_ner.py [-h] --data_dir DATA_DIR --model_type MODEL_TYPE\n",
    "                  --model_name_or_path MODEL_NAME_OR_PATH --output_dir\n",
    "                  OUTPUT_DIR [--labels LABELS] [--config_name CONFIG_NAME]\n",
    "                  [--tokenizer_name TOKENIZER_NAME] [--cache_dir CACHE_DIR]\n",
    "                  [--max_seq_length MAX_SEQ_LENGTH] [--do_train] [--do_eval]\n",
    "                  [--do_predict] [--evaluate_during_training]\n",
    "                  [--do_lower_case]\n",
    "                  [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
    "                  [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
    "                  [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
    "                  [--learning_rate LEARNING_RATE]\n",
    "                  [--weight_decay WEIGHT_DECAY] [--adam_epsilon ADAM_EPSILON]\n",
    "                  [--max_grad_norm MAX_GRAD_NORM]\n",
    "                  [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
    "                  [--max_steps MAX_STEPS] [--warmup_steps WARMUP_STEPS]\n",
    "                  [--logging_steps LOGGING_STEPS] [--save_steps SAVE_STEPS]\n",
    "                  [--eval_all_checkpoints] [--no_cuda]\n",
    "                  [--overwrite_output_dir] [--overwrite_cache] [--seed SEED]\n",
    "                  [--fp16] [--fp16_opt_level FP16_OPT_LEVEL]\n",
    "                  [--local_rank LOCAL_RANK] [--server_ip SERVER_IP]\n",
    "                  [--server_port SERVER_PORT]\n",
    "</pre></blockquote>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter logging_steps=1 causes stats to be written to tensorboard event file\n",
    "# every 1 minibatch. The default is 500 which may not generate enough content for this demo.\n",
    "estimator = PyTorch(entry_point='transformers-train.py',\n",
    "                    source_dir='./transformers-scripts',\n",
    "                    role=get_execution_role(),\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.m5.large',\n",
    "                    framework_version='1.3.1',\n",
    "                    py_version='py3',\n",
    "                    debugger_hook_config=False,\n",
    "                    hyperparameters={\n",
    "                        'num_train_epochs': 5.0,\n",
    "                        'model_type': 'roberta',\n",
    "                        'model_name_or_path': 'roberta-base',\n",
    "                        'logging_steps': 1\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will start a training job. The training job will download a few hundred MB of pretrained model, and this may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train': s3_input(train), 'dev': s3_input(dev), 'label': s3_input(label)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize training progress\n",
    "\n",
    "The tranformers's NER script records the training performance to a Tensorboard event file, and our entrypoint script ensures that SageMaker picks it up and upload it as `output.tar.gz`. We're going to install Tensorboard on this notebook instance, then visualize the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extract training output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tensorboard event file to this notebook instance.\n",
    "output_tgz = estimator.model_data.replace('model.tar.gz', 'output.tar.gz')\n",
    "print('Output file is', output_tgz)\n",
    "with fs.open(output_tgz, 'rb') as f:\n",
    "    with tarfile.open(None, 'r', f) as tgz:\n",
    "        tgz.extractall('.')\n",
    "\n",
    "print('Extracted to this instance:')\n",
    "!ls -alR runs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a terminal, then do this:\n",
    "\n",
    "```bash\n",
    "# The conda environment name is python3, which should match the kernel used by this notebook.\n",
    "# If this notebook uses a different kernel, you must activate the matching conda environment.\n",
    "source activate python3\n",
    "tensorboard --logdir=/home/ec2-user/SageMaker/amazon-sagemaker-groundtruth-ner/notebooks/runs\n",
    "```\n",
    "\n",
    "Then, open [this link](/proxy/6006/) in a new tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
